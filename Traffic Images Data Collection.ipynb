{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4aaabe1",
   "metadata": {},
   "source": [
    "**Using traffic images V1 API from data.gov.sg instead of LTA DataMall traffic images V2 API, because with V1 we can set the datetime parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9debb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c0e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = { 'AccountKey' : 'ZSRd6ixqSy+V+GnHTV7/iQ==',\n",
    "             'accept' : 'application/json'} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da75cf20",
   "metadata": {},
   "source": [
    "**For the traffic images, we can actually query it for a specific timeframe by including the datetime as a parameter, meaning it doesn't have to be real-time. <br> <br> Ideally I would want to get the data for 365 days. The problem is that would simply take too long. <br> 1 query (90 pictures) takes around 40 seconds in average (based on %timeit). If we use 5 minutes interval, that would mean 40 x 12 = 480 seconds, 8 minutes for 1 hour of data. Times that by 24 hours, and it would take 192 hours, around 3 hours for only 1 day of data. <br> <br> Of course that is alright, but it would be nicer if we could make the processing faster, and get data for 1 month. <br> The long processing time is because we need to perform object detection, we can use a faster model but that would sacrifice the accuracy of the detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0af808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(date):\n",
    "    \n",
    "    image_url = \"https://api.data.gov.sg/v1/transport/traffic-images\"\n",
    "    \n",
    "    params = {\"date_time\": date.strftime(\"%Y-%m-%dT%H:%M:%S+08:00\")}\n",
    "    \n",
    "    response = requests.get(image_url, params=params)\n",
    "    \n",
    "    #filename = datetime_value.strftime('%Y-%m-%d_%H-%M-%S.jpg')\n",
    "    \n",
    "    if response.json()[\"items\"]:\n",
    "        for i in response.json()[\"items\"]: \n",
    "            for camera in i[\"cameras\"]:                       \n",
    "                image = requests.get(camera[\"image\"])\n",
    "                camera_id = camera[\"camera_id\"]\n",
    "                timestamp = camera[\"timestamp\"]\n",
    "                \n",
    "                datetime_object = datetime.strptime(camera[\"timestamp\"], \"%Y-%m-%dT%H:%M:%S+08:00\")\n",
    "                datetime_new_format = datetime_object.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "                filepath = \"./dataset/\"+datetime_new_format+\" \"+camera[\"camera_id\"]+\".jpg\"\n",
    "                \n",
    "                pic_url = \"image.jpg\"\n",
    "                \n",
    "                file = open(pic_url, \"wb\")\n",
    "                file.write(image.content)\n",
    "                file.close()\n",
    "                \n",
    "                from_static_image(camera_id, timestamp)\n",
    "                \n",
    "                os.remove(pic_url)\n",
    "                \n",
    "                '''\n",
    "                If we simply want to save the image files:\n",
    "                \n",
    "                datetime_object = datetime.strptime(camera[\"timestamp\"], \"%Y-%m-%dT%H:%M:%S+08:00\")\n",
    "                datetime_new_format = datetime_object.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "                filepath = \"./dataset/\"+datetime_new_format+\" \"+camera[\"camera_id\"]+\".jpg\"\n",
    "                \n",
    "                file = open(filepath, \"wb\")\n",
    "                file.write(image.content)\n",
    "                file.close()\n",
    "                '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5fc73a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "# Detection confidence threshold\n",
    "confThreshold = 0.2\n",
    "nmsThreshold = 0.2\n",
    "\n",
    "# Middle cross line position\n",
    "middle_line_position = 225   \n",
    "up_line_position = middle_line_position - 15\n",
    "down_line_position = middle_line_position + 15\n",
    "\n",
    "# Store Coco Names in a list\n",
    "classesFile = \"coco.names\"\n",
    "classNames = open(classesFile).read().strip().split('\\n')\n",
    "print(len(classNames), classNames)\n",
    "\n",
    "# Model Files\n",
    "modelConfiguration = 'yolov3-320.cfg'\n",
    "modelWeights = 'yolov3.weights'\n",
    "\n",
    "# Load the network model\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "# Configure the network backend\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Define random color for each class\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
    "\n",
    "def postProcess(outputs, img):\n",
    "    required_class_index = [2, 3, 5, 7]\n",
    "    detected_classNames = []\n",
    "    height, width = img.shape[:2]\n",
    "    boxes = []\n",
    "    classIds = []\n",
    "    confidence_scores = []\n",
    "    detection = []\n",
    "\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if classId in required_class_index and confidence > confThreshold:\n",
    "                w, h = int(det[2] * width), int(det[3] * height)\n",
    "                x, y = int((det[0] * width) - w / 2), int((det[1] * height) - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                classIds.append(classId)\n",
    "                confidence_scores.append(float(confidence))\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
    "\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "            color = [int(c) for c in colors[classIds[i]]]\n",
    "            name = classNames[classIds[i]]\n",
    "            detected_classNames.append(name)\n",
    "            # Draw classname and confidence score\n",
    "            cv2.putText(img, f'{name.upper()} {int(confidence_scores[i] * 100)}%',\n",
    "                        (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            # Draw bounding rectangle\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "            detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n",
    "\n",
    "    return detected_classNames, img\n",
    "\n",
    "def from_static_image(camera_id, timestamp):\n",
    "    \n",
    "    image = \"image.jpg\"\n",
    "    \n",
    "    input_size = 320\n",
    "    img = cv2.imread(image)\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "    # Set the input of the network\n",
    "    net.setInput(blob)\n",
    "    layersNames = net.getLayerNames()\n",
    "    outputNames = [(layersNames[i - 1]) for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Feed data to the network\n",
    "    outputs = net.forward(outputNames)\n",
    "\n",
    "    # Find the objects from the network output\n",
    "    detected_classNames, output_img = postProcess(outputs, img)\n",
    "\n",
    "    # Count the frequency of detected classes\n",
    "    frequency = collections.Counter(detected_classNames)\n",
    "\n",
    "    num_vehicles = 0\n",
    "    for freq_item in frequency:\n",
    "        num_vehicles += frequency[freq_item]\n",
    "\n",
    "    # Display the output image\n",
    "    #cv2.imshow(\"Detected Image\", output_img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    # Print the detected class names\n",
    "    #print(\"Detected Classes:\")\n",
    "    #for class_name in detected_classNames:\n",
    "    #    print(class_name)\n",
    "    \n",
    "    global df\n",
    "    \n",
    "    distance = \n",
    "    \n",
    "    new_row = {'Timestamp': timestamp, 'Camera_ID': camera_id, 'Vehicle_Count':num_vehicles}\n",
    "    \n",
    "    new_df = pd.DataFrame([new_row])\n",
    "\n",
    "    # Concatenate the new DataFrame with the existing DataFrame\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d31c6d",
   "metadata": {},
   "source": [
    "**For one day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f92de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    now = datetime.now()\n",
    "\n",
    "    # Calculate datetime for yesterday\n",
    "    yesterday = now - timedelta(days=1)\n",
    "\n",
    "    # Set the starting datetime for the interval\n",
    "    current_datetime = datetime(yesterday.year, yesterday.month, yesterday.day, 0, 0)\n",
    "\n",
    "    # Generate datetime values in 5-minute intervals until now\n",
    "    while current_datetime <= now:\n",
    "        #print(current_datetime)\n",
    "        current_datetime += timedelta(minutes=5)\n",
    "        #get_image(current_datetime)\n",
    "\n",
    "        get_images(current_datetime)\n",
    "    \n",
    "    \n",
    "        \n",
    "    df.to_csv('./traffic_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb039d",
   "metadata": {},
   "source": [
    "**For one hour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c97777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-05 21:00:00\n",
      "2023-06-05 21:05:00\n",
      "2023-06-05 21:10:00\n",
      "2023-06-05 21:15:00\n",
      "2023-06-05 21:20:00\n",
      "2023-06-05 21:25:00\n",
      "2023-06-05 21:30:00\n",
      "2023-06-05 21:35:00\n",
      "2023-06-05 21:40:00\n",
      "2023-06-05 21:45:00\n",
      "2023-06-05 21:50:00\n",
      "2023-06-05 21:55:00\n",
      "2023-06-05 22:00:00\n",
      "2023-06-05 22:05:00\n",
      "2023-06-05 22:10:00\n",
      "2023-06-05 22:15:00\n",
      "2023-06-05 22:20:00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    now = datetime.now()\n",
    "\n",
    "    # Calculate datetime for 1 hour ago\n",
    "    one_hour_ago = now - timedelta(hours=1)\n",
    "\n",
    "    # Set the starting datetime for the interval\n",
    "    current_datetime = datetime(one_hour_ago.year, one_hour_ago.month, one_hour_ago.day, one_hour_ago.hour, 0)\n",
    "\n",
    "    # Generate datetime values in 1-hour intervals until now\n",
    "    while current_datetime <= now:\n",
    "        # Perform operations with current_datetime\n",
    "        # get_image(current_datetime)\n",
    "        get_images(current_datetime)\n",
    "        print(current_datetime)\n",
    "        current_datetime += timedelta(minutes=5)\n",
    "    \n",
    "    \n",
    "        \n",
    "    df.to_csv('./traffic_count.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c95aed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
